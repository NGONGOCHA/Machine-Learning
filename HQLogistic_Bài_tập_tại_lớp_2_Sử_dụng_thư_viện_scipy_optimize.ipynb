{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUVbofbvmFdf0hSDLfjHAS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NGONGOCHA/Machine-Learning/blob/main/HQLogistic_B%C3%A0i_t%E1%BA%ADp_t%E1%BA%A1i_l%E1%BB%9Bp_2_S%E1%BB%AD_d%E1%BB%A5ng_th%C6%B0_vi%E1%BB%87n_scipy_optimize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5yNXcynXGfy",
        "outputId": "0f8a37ea-e868-419d-f8f7-872919cb2eb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIVn1uVkWnsC",
        "outputId": "3607fa9a-9016-4b9a-cdd4-55712553dc0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.5067801656080071\n",
            "-0.3270580397857178\n",
            "Ket qua la: \n",
            "\t\tTrong so w toi uu la:  [ 1.71841797 14.38833747 13.75343322]\n",
            "\t\tGia tri Loss toi uu:  0.2034977016212829\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from scipy import optimize\n",
        "\n",
        "def readData(filename, folder=\"\"):\n",
        "    data = np.loadtxt(os.path.join(folder, filename), delimiter = ',')\n",
        "    X = data[:,:-1]\n",
        "    y = data[:, -1]\n",
        "    m = X.shape[0]\n",
        "    n = X.shape[1]\n",
        "    X = np.reshape(X, (m,n))\n",
        "#Do w là vector hàng (n, ) nên khi nhân với X.w sẽ cho ra vector hàng (m, )\n",
        "#Nên y giữ nguyên là vector hàng chứ không reshape thành vector cột dạng ma trận (m,1)\n",
        "#Them cot x0 = 1 vao X\n",
        "    x0 = np.ones((m,1))\n",
        "    X = np.column_stack([x0, X])\n",
        "    return X, y\n",
        "\n",
        "def featureVectorScaling(data):\n",
        "    avg = np.mean(data)\n",
        "    sln = data.max()\n",
        "    snn = data.min()\n",
        "    data_scl = (data - avg)/(sln - snn)\n",
        "    print(data_scl[1])\n",
        "    return data_scl\n",
        "\n",
        "def normalizeData(X):\n",
        "    X_scl = X[:, 0]\n",
        "    for i in range(1, X.shape[1]):\n",
        "        scl = featureVectorScaling(X[:, i])\n",
        "        X_scl = np.column_stack([X_scl, scl])\n",
        "    return X_scl\n",
        "\n",
        "#ham  hw(X)\n",
        "def sigmoid(X, w):\n",
        "    result = 1/(1 + np.exp(-np.dot(X, w)))\n",
        "    return result\n",
        "\n",
        "#Chỉnh sửa lại hàm mất mát J(w) cho phù hợp với yêu cầu của hàm minimize của scipy\n",
        "#Thứ tự xuất hiện của các tham số được đổi lại là w, X, y\n",
        "def loss(w, X, y):\n",
        "    m = X.shape[0]\n",
        "    h = sigmoid(X, w)\n",
        "    result = (-1 / m) * np.sum(np.dot(y.T, np.log(h)) + np.dot((1 - y).T, np.log(1 - h)))\n",
        "    return result\n",
        "\n",
        "def scipy_optimize(X,y,w,n_iters):\n",
        "#Thứ tự xuất hiện các tham số của hàm loss phải đổi lại theo thứ tự trong optimize.minimize là\n",
        "#loss(w, X, y)\n",
        "    result = optimize.minimize(fun=loss, x0=w, args=(X,y),\n",
        "                               method='L-BFGS-B',\n",
        "                               options={\"maxiter\":n_iters} )\n",
        "    w_optimal = result.x\n",
        "    J_optimal = result.fun\n",
        "    return w_optimal, J_optimal\n",
        "\n",
        "def main():\n",
        "    X, y = readData('/content/drive/MyDrive/Classroom/Học máy 1 Phần cơ sở/ex2data1.txt')\n",
        "    X = normalizeData(X)\n",
        "    n = X.shape[1]\n",
        "#Lưu ý: w trong thuật toán của scipy là vector hàng tương ứng 1d-array trong numpy\n",
        "    w = np.zeros(n)\n",
        "    n_iters = 2000\n",
        "    w_opt, J_opt = scipy_optimize(X,y,w, n_iters)\n",
        "    print(\"Ket qua la: \")\n",
        "    print('\\t\\tTrong so w toi uu la: ', w_opt)\n",
        "    print('\\t\\tGia tri Loss toi uu: ', J_opt)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}